# milestone：构建小规模领域知识图谱
## 组队情况
| 身份 | 学号 | 姓名 |
| :----: | :----: | :----: |
|队长|221900103|许梁超|
|队员|221900068|张淳皓|
|队员|221900084|王诗瑶|
## 进展

### 命名实体识别
- 使用SpaCy提供的预训练模型进行实体识别并分类，生成json文件存储实体识别结果
- 使用Bert模型在CoNLL2003数据集上进行微调，训练出微调模型
- 使用微调后的NER模型，进行实体识别并分类，同样json文件存储实体识别结果
- 评估Spacy实体识别模型在 CoNLL2003测试集上的表现
- 评估微调后的BERT的实体识别模型在 CoNLL2003测试集上的表现，并比较

### 关系抽取和知识图谱


## 初步成果

### 命名实体识别

#### 实体识别结果
##### 使用SpaCy提供的预训练模型——存储于 conll2003_processed
- 示例： "input_text": "Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .",
- "entities": [
      [
        "Germany",
        "LOC"
      ],
      [
        "the European Union 's",
        "ORG"
      ],
      [
        "Werner Zwingmann",
        "PER"
      ],
      [
        "Wednesday",
        "MISC"
      ],
      [
        "Britain",
        "LOC"
      ]
    ]
##### Bert微调后的NER模型——存储于 conll2003_bert_processed
- 示例："Germany 's representative to the European Union 's veterinary committee Werner Zwingmann said on Wednesday consumers should buy sheepmeat from countries other than Britain until the scientific advice was clearer .",
- "entities": [
      [
        "Germany",
        "LOC"
      ],
      [
        "European Union",
        "ORG"
      ],
      [
        "Werner Zwingmann",
        "PER"
      ],
      [
        "Britain",
        "LOC"
      ]
    ]

#### 模型评估
##### 使用SpaCy提供的预训练模型

| 标签   | precision        | recall           | f1-score         | support |
|--------|------------------|------------------|------------------|---------|
| LOC    | 0.7105398457583547 | 0.8285371702637889 | 0.765015222806532 | 1668.0  |
| MISC   | 0.015262860373092142 | 0.07692307692307693 | 0.02547169811320755 | 702.0   |
| ORG    | 0.36901913875598086 | 0.37146297411198076 | 0.3702370237023702 | 1661.0  |
| PER    | 0.8375886524822695 | 0.730364873222016 | 0.7803105384869508 | 1617.0  |
| micro avg | 0.3775831873905429 | 0.5725920679886686 | 0.4550763385632871 | 5648.0  |
| macro avg | 0.4831026243424243 | 0.5018220236302157 | 0.4852586207772651 | 5648.0  |
| weighted avg | 0.560059601849214 | 0.5725920679886686 | 0.5613761262074722 | 5648.0  |

##### 使用Bert微调后的NER模型

| 标签         | precision        | recall           | f1-score         | support |
|--------------|------------------|------------------|------------------|---------|
| LOC          | 0.9353202282815473 | 0.8842925659472423 | 0.9090909090909091 | 1668.0  |
| MISC         | 0.7789317507418397 | 0.7478632478632479 | 0.7630813953488371 | 702.0   |
| ORG          | 0.8870266914959652 | 0.8603251053582179 | 0.8734718826405868 | 1661.0  |
| PER          | 0.9699103713188221 | 0.9369202226345084 | 0.9531299150676315 | 1617.0  |
| micro avg    | 0.911504424778761  | 0.8753541076487252 | 0.8930635838150289 | 5648.0  |
| macro avg    | 0.8927972604595436 | 0.857350285450804  | 0.8746935255369911 | 5648.0  |
| weighted avg | 0.9115829735821045 | 0.8753541076487252 | 0.8930762474555408 | 5648.0  |

##### 评估分析
- 分类指标上，SpaCy 预训练模型LOC 类别表现中等，PER 类别存在漏检，而 ORG和 MISC识别效果极差，反映出对复杂及低频实体的特征学习不足；Bert 微调 NER 模型通过微调显著提升各维度：LOC、PER 类别 表现很好，ORG 和 MISC 夜有所提升，表明其通过深度语义理解和领域数据适配，有效优化了复杂实体识别能力。
- 整体指标上，Bert 模型的 micro avg precision、recall和 f1-score均远超 SpaCy 模型，macro avg 和 weighted avg 指标也显著更优，表明其在各类别上表现更均衡，对整体样本的分类能力更强。

### 关系抽取和知识图谱

## 下一步计划
完成知识表示学习、NE图谱动态更新和增量学习的任务
### 知识表示学习

#### 目标：训练实体与关系的低维向量表示

#### 任务分解
- 数据准备与模型选择：将三元组划分为训练集/验证集/测试集，使用PyKEEN或OpenKE等框架下的模型

- 训练与评估：设置训练轮次和批大小，使用某些指标评估模型性能，并保存最优模型参数

- 探索不同模型：对比TransE（适合层级关系）、ComplEx（处理对称/逆关系）和RotatE（建模复杂关系）在不同关系类型上的表现，记录各模型训练时间和预测准确率

#### 技术点：采样策略、损失函数选择、训练加速技巧

### 阶段四：NE图谱动态更新和增量学习

#### 目标：支持新数据增量更新，避免全量重新训练

##### 任务分解：

- ​图谱更新策略：设计基于规则和嵌入相似度的冲突检测机制，开发实体对齐算法，实现新增三元组的自动化合并与版本化存储，确保知识一致性

- 增量训练方法：使用continual KGE技术，在动态知识图谱中增量学习新知识同时保留历史知识

- 图演化表示方法：使用Dynamic KGE技术，通过时间编码机制将时序信息融入实体和关系的向量表示中，建模知识图谱随时间演化的表示学习方法

#### 技术点：​图谱更新策略、增量训练方法、图演化表示方法
